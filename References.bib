@article{DWIVEDI2023102642,
  title = {Opinion Paper: “So what if ChatGPT wrote it?” Multidisciplinary perspectives on opportunities, challenges and implications of generative conversational AI for research, practice and policy},
  journal = {International Journal of Information Management},
  volume = {71},
  pages = {102642},
  year = {2023},
  issn = {0268-4012},
  doi = {https://doi.org/10.1016/j.ijinfomgt.2023.102642},
  url = {https://www.sciencedirect.com/science/article/pii/S0268401223000233},
  author = {Yogesh K. Dwivedi and Nir Kshetri and Laurie Hughes and Emma Louise Slade and Anand Jeyaraj and Arpan Kumar Kar and Abdullah M. Baabdullah and Alex Koohang and Vishnupriya Raghavan and Manju Ahuja and Hanaa Albanna and Mousa Ahmad Albashrawi and Adil S. Al-Busaidi and Janarthanan Balakrishnan and Yves Barlette and Sriparna Basu and Indranil Bose and Laurence Brooks and Dimitrios Buhalis and Lemuria Carter and Soumyadeb Chowdhury and Tom Crick and Scott W. Cunningham and Gareth H. Davies and Robert M. Davison and Rahul Dé and Denis Dennehy and Yanqing Duan and Rameshwar Dubey and Rohita Dwivedi and John S. Edwards and Carlos Flavián and Robin Gauld and Varun Grover and Mei-Chih Hu and Marijn Janssen and Paul Jones and Iris Junglas and Sangeeta Khorana and Sascha Kraus and Kai R. Larsen and Paul Latreille and Sven Laumer and F. Tegwen Malik and Abbas Mardani and Marcello Mariani and Sunil Mithas and Emmanuel Mogaji and Jeretta Horn Nord and Siobhan O’Connor and Fevzi Okumus and Margherita Pagani and Neeraj Pandey and Savvas Papagiannidis and Ilias O. Pappas and Nishith Pathak and Jan Pries-Heje and Ramakrishnan Raman and Nripendra P. Rana and Sven-Volker Rehm and Samuel Ribeiro-Navarrete and Alexander Richter and Frantz Rowe and Suprateek Sarker and Bernd Carsten Stahl and Manoj Kumar Tiwari and Wil {van der Aalst} and Viswanath Venkatesh and Giampaolo Viglia and Michael Wade and Paul Walton and Jochen Wirtz and Ryan Wright},
  keywords = {Conversational agent, Generative artificial intelligence, Generative AI, ChatGPT, Large language models},
  abstract = {Transformative artificially intelligent tools, such as ChatGPT, designed to generate sophisticated text indistinguishable from that produced by a human, are applicable across a wide range of contexts. The technology presents opportunities as well as, often ethical and legal, challenges, and has the potential for both positive and negative impacts for organisations, society, and individuals. Offering multi-disciplinary insight into some of these, this article brings together 43 contributions from experts in fields such as computer science, marketing, information systems, education, policy, hospitality and tourism, management, publishing, and nursing. The contributors acknowledge ChatGPT’s capabilities to enhance productivity and suggest that it is likely to offer significant gains in the banking, hospitality and tourism, and information technology industries, and enhance business activities, such as management and marketing. Nevertheless, they also consider its limitations, disruptions to practices, threats to privacy and security, and consequences of biases, misuse, and misinformation. However, opinion is split on whether ChatGPT’s use should be restricted or legislated. Drawing on these contributions, the article identifies questions requiring further research across three thematic areas: knowledge, transparency, and ethics; digital transformation of organisations and societies; and teaching, learning, and scholarly research. The avenues for further research include: identifying skills, resources, and capabilities needed to handle generative AI; examining biases of generative AI attributable to training datasets and processes; exploring business and societal contexts best suited for generative AI implementation; determining optimal combinations of human and generative AI for various tasks; identifying ways to assess accuracy of text produced by generative AI; and uncovering the ethical and legal issues in using generative AI across different contexts.}
}

@book{10.7551/mitpress/4626.001.0001,
  author = {Haugeland, John},
  title = "{Mind Design II: Philosophy, Psychology, and Artificial Intelligence}",
  publisher = {The MIT Press},
  year = {1997},
  month = {03},
  abstract = "{Mind design is the endeavor to understand mind (thinking, intellect) in terms of its design (how it is built, how it works). Unlike traditional empirical psychology, it is more oriented toward the "how" than the "what." An experiment in mind design is more likely to be an attempt to build something and make it work—as in artificial intelligence—than to observe or analyze what already exists. Mind design is psychology by reverse engineering.When Mind Design was first published in 1981, it became a classic in the then-nascent fields of cognitive science and AI. This second edition retains four landmark essays from the first, adding to them one earlier milestone (Turing's "Computing Machinery and Intelligence") and eleven more recent articles about connectionism, dynamical systems, and symbolic versus nonsymbolic models. The contributors are divided about evenly between philosophers and scientists. Yet all are "philosophical" in that they address fundamental issues and concepts; and all are "scientific" in that they are technically sophisticated and concerned with concrete empirical research.Contributors Rodney A. Brooks, Paul M. Churchland, Andy Clark, Daniel C. Dennett, Hubert L. Dreyfus, Jerry A. Fodor, Joseph Garon, John Haugeland, Marvin Minsky, Allen Newell, Zenon W. Pylyshyn, William Ramsey, Jay F. Rosenberg, David E. Rumelhart, John R. Searle, Herbert A. Simon, Paul Smolensky, Stephen Stich, A.M. Turing, Timothy van Gelder}",
  isbn = {9780262275071},
  doi = {10.7551/mitpress/4626.001.0001},
  url = {https://doi.org/10.7551/mitpress/4626.001.0001},
}

@article{handler2008avoidanotheraiwinter,
  author={Hendler, James},
  journal={IEEE Intelligent Systems},
  title={Avoiding Another AI Winter},
  year={2008},
  volume={23},
  number={2},
  pages={2-4},
  keywords={Artificial intelligence;Europe;Educational institutions;Computer science;Consumer products;Medical services;Biomedical equipment;Web search;Data mining;Information filtering;artificial intelligence;AI Winter;computer science;expert systems;DARPA;Sixth Framework Programme;Seventh Framework Programme;Hai Zhuge},
  doi={10.1109/MIS.2008.20}
}

@article{10.1093/mind/LIX.236.433,
  author = {TURING, A. M.},
  title = "{I.—COMPUTING MACHINERY AND INTELLIGENCE}",
  journal = {Mind},
  volume = {LIX},
  number = {236},
  pages = {433-460},
  year = {1950},
  month = {10},
  issn = {0026-4423},
  doi = {10.1093/mind/LIX.236.433},
  url = {https://doi.org/10.1093/mind/LIX.236.433},
  eprint = {https://academic.oup.com/mind/article-pdf/LIX/236/433/30123314/lix-236-433.pdf},
}

@misc{brown2020languagemodelsfewshotlearners,
  title={Language Models are Few-Shot Learners},
  author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
  year={2020},
  eprint={2005.14165},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2005.14165},
}

@misc{keles2022computationalcomplexityselfattention,
  title={On The Computational Complexity of Self-Attention},
  author={Feyza Duman Keles and Pruthuvi Mahesakya Wijewardena and Chinmay Hegde},
  year={2022},
  eprint={2209.04881},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2209.04881},
}

@misc{wei2022emergentabilitieslargelanguage,
  title={Emergent Abilities of Large Language Models},
  author={Jason Wei and Yi Tay and Rishi Bommasani and Colin Raffel and Barret Zoph and Sebastian Borgeaud and Dani Yogatama and Maarten Bosma and Denny Zhou and Donald Metzler and Ed H. Chi and Tatsunori Hashimoto and Oriol Vinyals and Percy Liang and Jeff Dean and William Fedus},
  year={2022},
  eprint={2206.07682},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2206.07682},
}

@article{elhage2022superposition,
  title={Toy Models of Superposition},
  author={Elhage, Nelson and Hume, Tristan and Olsson, Catherine and Schiefer, Nicholas and Henighan, Tom and Kravec, Shauna and Hatfield-Dodds, Zac and Lasenby, Robert and Drain, Dawn and Chen, Carol and Grosse, Roger and McCandlish, Sam and Kaplan, Jared and Amodei, Dario and Wattenberg, Martin and Olah, Christopher},
  year={2022},
  journal={Transformer Circuits Thread},
  url={https://transformer-circuits.pub/2022/toy_model/index.html}
}

@article{lindsey2024sparsecrosscoders,
  title={Sparse Crosscoders for Cross-Layer Features and Model Diffing},
  author={Lindsey, Jack and Templeton, Adly and Marcus, Jonathan and Conerly, Thomas and Batson, Joshua and Olah, Christopher},
  year={2024},
  journal={Transformer Circuits Thread},
  url={https://transformer-circuits.pub/2024/crosscoders/index.html}
}

@inproceedings{mikolov-etal-2013-linguistic,
  title = "Linguistic Regularities in Continuous Space Word Representations",
  author = "Mikolov, Tomas  and
    Yih, Wen-tau  and
    Zweig, Geoffrey",
  editor = "Vanderwende, Lucy  and
    Daum{\'e} III, Hal  and
    Kirchhoff, Katrin",
  booktitle = "Proceedings of the 2013 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies",
  month = jun,
  year = "2013",
  address = "Atlanta, Georgia",
  publisher = "Association for Computational Linguistics",
  url = "https://aclanthology.org/N13-1090",
  pages = "746--751",
}

@misc{mikolov2013efficientestimationwordrepresentations,
  title={Efficient Estimation of Word Representations in Vector Space},
  author={Tomas Mikolov and Kai Chen and Greg Corrado and Jeffrey Dean},
  year={2013},
  eprint={1301.3781},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/1301.3781},
}

@article{bricken2023monosemanticity,
  title={Towards Monosemanticity: Decomposing Language Models With Dictionary Learning},
  author={Bricken, Trenton and Templeton, Adly and Batson, Joshua and Chen, Brian and Jermyn, Adam and Conerly, Tom and Turner, Nick and Anil, Cem and Denison, Carson and Askell, Amanda and Lasenby, Robert and Wu, Yifan and Kravec, Shauna and Schiefer, Nicholas and Maxwell, Tim and Joseph, Nicholas and Hatfield-Dodds, Zac and Tamkin, Alex and Nguyen, Karina and McLean, Brayden and Burke, Josiah E and Hume, Tristan and Carter, Shan and Henighan, Tom and Olah, Christopher},
  year={2023},
  journal={Transformer Circuits Thread},
  url={https://transformer-circuits.pub/2023/monosemantic-features/index.html}
}

@article{templeton2024scaling,
  title={Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet},
  author={Templeton, Adly and Conerly, Tom and Marcus, Jonathan and Lindsey, Jack and Bricken, Trenton and Chen, Brian and Pearce, Adam and Citro, Craig and Ameisen, Emmanuel and Jones, Andy and Cunningham, Hoagy and Turner, Nicholas L and McDougall, Callum and MacDiarmid, Monte and Freeman, C. Daniel and Sumers, Theodore R. and Rees, Edward and Batson, Joshua and Jermyn, Adam and Carter, Shan and Olah, Chris and Henighan, Tom},
  year={2024},
  journal={Transformer Circuits Thread},
  url={https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html}
}

@misc{kaplan2020scalinglawsneurallanguage,
  title={Scaling Laws for Neural Language Models},
  author={Jared Kaplan and Sam McCandlish and Tom Henighan and Tom B. Brown and Benjamin Chess and Rewon Child and Scott Gray and Alec Radford and Jeffrey Wu and Dario Amodei},
  year={2020},
  eprint={2001.08361},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2001.08361},
}

@misc{croft2023llm,
  title={LLM Visualization},
  author={Croft, Benjamin},
  year={2023},
  howpublished={\url{https://bbycroft.net/llm}},
  note={Accessed: 2023-06-28}
}

@misc{jambateam2024jamba15hybridtransformermambamodels,
  title={Jamba-1.5: Hybrid Transformer-Mamba Models at Scale},
  author={Jamba Team and Barak Lenz and Alan Arazi and Amir Bergman and Avshalom Manevich and Barak Peleg and Ben Aviram and Chen Almagor and Clara Fridman and Dan Padnos and Daniel Gissin and Daniel Jannai and Dor Muhlgay and Dor Zimberg and Edden M Gerber and Elad Dolev and Eran Krakovsky and Erez Safahi and Erez Schwartz and Gal Cohen and Gal Shachaf and Haim Rozenblum and Hofit Bata and Ido Blass and Inbal Magar and Itay Dalmedigos and Jhonathan Osin and Julie Fadlon and Maria Rozman and Matan Danos and Michael Gokhman and Mor Zusman and Naama Gidron and Nir Ratner and Noam Gat and Noam Rozen and Oded Fried and Ohad Leshno and Omer Antverg and Omri Abend and Opher Lieber and Or Dagan and Orit Cohavi and Raz Alon and Ro'i Belson and Roi Cohen and Rom Gilad and Roman Glozman and Shahar Lev and Shaked Meirom and Tal Delbari and Tal Ness and Tomer Asida and Tom Ben Gal and Tom Braude and Uriya Pumerantz and Yehoshua Cohen and Yonatan Belinkov and Yuval Globerson and Yuval Peleg Levy and Yoav Shoham},
  year={2024},
  eprint={2408.12570},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2408.12570},
}

@misc{tao2024machineassisted,
  title={Machine-Assisted Proofs},
  author={Terence Tao},
  year={2024},
  month={March},
  howpublished={\url{https://terrytao.wordpress.com/wp-content/uploads/2024/03/machine-assisted-proof-notices.pdf}},
  note={Notices of the American Mathematical Society}
}

@misc{gartner2024multimodal,
  title={Gartner Predicts 40 Percent of Generative AI Solutions Will Be Multimodal By 2027},
  author={Gartner},
  year={2024},
  month={09},
  day={09},
  howpublished={\url{https://www.gartner.com/en/newsroom/press-releases/2024-09-09-gartner-predicts-40-percent-of-generative-ai-solutions-will-be-multimodal-by-2027}},
  note={Press Release}
}

@misc{nanda2023concrete,
  title={Concrete Steps to Get Started in Transformer Mechanistic Interpretability},
  author={Neel Nanda},
  year={2023},
  howpublished={\url{https://www.neelnanda.io/mechanistic-interpretability/getting-started}},
  note={Blog post}
}

@misc{nijkamp2023xgen7btechnicalreport,
  title={XGen-7B Technical Report},
  author={Erik Nijkamp and Tian Xie and Hiroaki Hayashi and Bo Pang and Congying Xia and Chen Xing and Jesse Vig and Semih Yavuz and Philippe Laban and Ben Krause and Senthil Purushwalkam and Tong Niu and Wojciech Kryściński and Lidiya Murakhovs'ka and Prafulla Kumar Choubey and Alex Fabbri and Ye Liu and Rui Meng and Lifu Tu and Meghana Bhat and Chien-Sheng Wu and Silvio Savarese and Yingbo Zhou and Shafiq Joty and Caiming Xiong},
  year={2023},
  eprint={2309.03450},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2309.03450},
}

@misc{dhuliawala2023chainofverificationreduceshallucinationlarge,
  title={Chain-of-Verification Reduces Hallucination in Large Language Models},
  author={Shehzaad Dhuliawala and Mojtaba Komeili and Jing Xu and Roberta Raileanu and Xian Li and Asli Celikyilmaz and Jason Weston},
  year={2023},
  eprint={2309.11495},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2309.11495},
}

@misc{béchard2024reducinghallucinationstructuredoutputs,
  title={Reducing hallucination in structured outputs via Retrieval-Augmented Generation},
  author={Patrice Béchard and Orlando Marquez Ayala},
  year={2024},
  eprint={2404.08189},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2404.08189},
}

@misc{xu2023multimodallearningtransformerssurvey,
  title={Multimodal Learning with Transformers: A Survey},
  author={Peng Xu and Xiatian Zhu and David A. Clifton},
  year={2023},
  eprint={2206.06488},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/2206.06488},
}

@misc{huang2023surveyhallucinationlargelanguage,
  title={A Survey on Hallucination in Large Language Models: Principles, Taxonomy, Challenges, and Open Questions},
  author={Lei Huang and Weijiang Yu and Weitao Ma and Weihong Zhong and Zhangyin Feng and Haotian Wang and Qianglong Chen and Weihua Peng and Xiaocheng Feng and Bing Qin and Ting Liu},
  year={2023},
  eprint={2311.05232},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2311.05232},
}

@misc{pozdniakov2024largelanguagemodelsmeet,
  title={Large Language Models Meet User Interfaces: The Case of Provisioning Feedback},
  author={Stanislav Pozdniakov and Jonathan Brazil and Solmaz Abdi and Aneesha Bakharia and Shazia Sadiq and Dragan Gasevic and Paul Denny and Hassan Khosravi},
  year={2024},
  eprint={2404.11072},
  archivePrefix={arXiv},
  primaryClass={cs.HC},
  url={https://arxiv.org/abs/2404.11072},
}

@misc{hao2022languagemodelsgeneralpurposeinterfaces,
  title={Language Models are General-Purpose Interfaces},
  author={Yaru Hao and Haoyu Song and Li Dong and Shaohan Huang and Zewen Chi and Wenhui Wang and Shuming Ma and Furu Wei},
  year={2022},
  eprint={2206.06336},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2206.06336},
}

@inproceedings{kwon2023efficient,
  title={Efficient Memory Management for Large Language Model Serving with PagedAttention},
  author={Woosuk Kwon and Zhuohan Li and Siyuan Zhuang and Ying Sheng and Lianmin Zheng and Cody Hao Yu and Joseph E. Gonzalez and Hao Zhang and Ion Stoica},
  booktitle={Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles},
  year={2023}
}

@misc{vaswani2023attentionneed,
  title={Attention Is All You Need},
  author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
  year={2023},
  eprint={1706.03762},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/1706.03762},
}

@article{srivastava_dropout_2014,
  title     = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
  author    = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  journal   = {Journal of Machine Learning Research},
  volume    = {15},
  number    = {56},
  pages     = {1929--1958},
  year      = {2014}
}

@book{aristotle_nicomachean_ethics,
  author    = {Aristotle},
  title     = {Nicomachean Ethics},
  translator = {Ross, W. D.},
  editor    = {Brown, Lesley},
  year      = {2009},
  publisher = {Oxford University Press},
  address   = {Oxford},
  series    = {Oxford World's Classics},
  isbn      = {978-0199213610}
}

@book{leibniz_selections_1951,
  title     = {Leibniz Selections},
  editor    = {Wiener, Philip P.},
  author    = {Leibniz, Gottfried Wilhelm},
  year      = {1951},
  publisher = {Charles Scribner's Sons},
  address   = {New York},
  pages     = {606}
}

@book{jackson_introduction_1998,
  author    = {Jackson, Peter},
  title     = {Introduction to Expert Systems},
  year      = {1998},
  edition   = {3},
  publisher = {Addison Wesley},
  address   = {Harlow, England},
  isbn      = {978-0-201-87686-4},
  pages     = {542},
  series    = {International computer science series}
}

@article{rosenblatt1958perceptron,
  author = {Rosenblatt, F.},
  year = {1958},
  title = {The perceptron: A probabilistic model for information storage and organization in the brain},
  journal = {Psychological Review},
  volume = {65},
  number = {6},
  pages = {386--408},
  doi = {10.1037/h0042519}
}

@book{10.7551/mitpress/5236.001.0001,
  author = {Rumelhart, David E. and McClelland, James L. and PDP Research Group},
  title = "{Parallel Distributed Processing, Volume 1: Explorations in the Microstructure of Cognition: Foundations}",
  publisher = {The MIT Press},
  year = {1986},
  month = {07},
  abstract = "{What makes people smarter than computers? These volumes by a pioneering neurocomputing group suggest that the answer lies in the massively parallel architecture of the human mind. They describe a new theory of cognition called connectionism that is challenging the idea of symbolic computation that has traditionally been at the center of debate in theoretical discussions about the mind. The authors' theory assumes the mind is composed of a great number of elementary units connected in a neural network. Mental processes are interactions between these units which excite and inhibit each other in parallel rather than sequential operations. In this context, knowledge can no longer be thought of as stored in localized structures; instead, it consists of the connections between pairs of units that are distributed throughout the network. Volume 1 lays the foundations of this exciting theory of parallel distributed processing, while Volume 2 applies it to a number of specific issues in cognitive science and neuroscience, with chapters describing models of aspects of perception, memory, language, and thought.Bradford Books imprint}",
  isbn = {9780262291408},
  doi = {10.7551/mitpress/5236.001.0001},
  url = {https://doi.org/10.7551/mitpress/5236.001.0001},
}

@article{ackley_learning_1985,
  title = {A Learning Algorithm for Boltzmann Machines},
  author = {Ackley, David H. and Hinton, Geoffrey E. and Sejnowski, Terrence J.},
  journal = {Cognitive Science},
  volume = {9},
  number = {1},
  pages = {147--169},
  year = {1985},
  publisher = {Wiley Online Library},
  doi = {10.1207/s15516709cog0901_7}
}

@misc{silver2017masteringchessshogiselfplay,
  title={Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm},
  author={David Silver and Thomas Hubert and Julian Schrittwieser and Ioannis Antonoglou and Matthew Lai and Arthur Guez and Marc Lanctot and Laurent Sifre and Dharshan Kumaran and Thore Graepel and Timothy Lillicrap and Karen Simonyan and Demis Hassabis},
  year={2017},
  eprint={1712.01815},
  archivePrefix={arXiv},
  primaryClass={cs.AI},
  url={https://arxiv.org/abs/1712.01815},
}

@article{carr2019thieves,
  title={Thieves of Experience: How Google and Facebook Corrupted Capitalism},
  author={Carr, Nicholas},
  journal={Los Angeles Review of Books},
  year={2019},
  month={January},
  day={15},
  url={https://lareviewofbooks.org/article/thieves-of-experience-how-google-and-facebook-corrupted-capitalism/},
  note={Review of "The Age of Surveillance Capitalism" by Shoshana Zuboff}
}

@book{atlasofai,
  ISBN = {9780300209570},
  URL = {http://www.jstor.org/stable/j.ctv1ghv45t},
  abstract = {
    The hidden costs of artificial intelligence, from natural
    resources and labor to privacy and freedom What happens
    when artificial intelligence saturates political life and depletes
    the planet? How is AI shaping our understanding of ourselves and
    our societies? In this book Kate Crawford reveals how this
    planetary network is fueling a shift toward undemocratic governance
    and increased inequality. Drawing on more than a decade of
    research, award-winning science, and technology, Crawford reveals
    how AI is a technology of extraction: from the energy and minerals
    needed to build and sustain its infrastructure, to the exploited
    workers behind "automated" services, to the data AI collects from
    us. Rather than taking a narrow focus on code and algorithms,
    Crawford offers us a political and a material perspective on what
    it takes to make artificial intelligence and where it goes wrong.
    While technical systems present a veneer of objectivity, they are
    always systems of power. This is an urgent account of what is at
    stake as technology companies use artificial intelligence to
    reshape the world.
  },
  author = {KATE CRAWFORD},
  publisher = {Yale University Press},
  title = {The Atlas of AI: Power, Politics, and the Planetary Costs of Artificial Intelligence},
  urldate = {2024-10-09},
  year = {2021}
}

@article{jordan2015machine,
  title={Machine learning: Trends, perspectives, and prospects},
  author={Jordan, Michael I and Mitchell, Tom M},
  journal={Science},
  volume={349},
  number={6245},
  pages={255--260},
  year={2015},
  publisher={American Association for the Advancement of Science}
}

@article{mckinsey2024techtrends,
  title={McKinsey technology trends outlook 2024},
  author={{McKinsey \& Company}},
  year={2024},
  url={https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-top-trends-in-tech},
  journal={McKinsey Digital},
  note={Accessed on October 09, 2024}
}

@incollection{dreyfus2008why,
  title={Why Heideggerian AI Failed and How Fixing It Would Require Making It More Heideggerian},
  author={Dreyfus, Hubert L.},
  booktitle={The Mechanical Mind in History},
  pages={331--362},
  year={2008},
  publisher={MIT Press},
  address={Cambridge, MA}
}

@book{dreyfus1972what,
  title={What Computers Can't Do: A Critique of Artificial Reason},
  author={Dreyfus, Hubert L.},
  year={1972},
  publisher={Harper \& Row},
  address={New York, NY},
  isbn={978-0060906139},
  edition={1st}
}

@article{zhang2020labelingmethod,
  AUTHOR = {Wu, Dingming and Wang, Xiaolong and Su, Jingyong and Tang, Buzhou and Wu, Shaocong},
  TITLE = {A Labeling Method for Financial Time Series Prediction Based on Trends},
  JOURNAL = {Entropy},
  VOLUME = {22},
  YEAR = {2020},
  NUMBER = {10},
  ARTICLE-NUMBER = {1162},
  URL = {https://www.mdpi.com/1099-4300/22/10/1162},
  PubMedID = {33286931},
  ISSN = {1099-4300},
  ABSTRACT = {Time series prediction has been widely applied to the finance industry in applications such as stock market price and commodity price forecasting. Machine learning methods have been widely used in financial time series prediction in recent years. How to label financial time series data to determine the prediction accuracy of machine learning models and subsequently determine final investment returns is a hot topic. Existing labeling methods of financial time series mainly label data by comparing the current data with those of a short time period in the future. However, financial time series data are typically non-linear with obvious short-term randomness. Therefore, these labeling methods have not captured the continuous trend features of financial time series data, leading to a difference between their labeling results and real market trends. In this paper, a new labeling method called “continuous trend labeling” is proposed to address the above problem. In the feature preprocessing stage, this paper proposed a new method that can avoid the problem of look-ahead bias in traditional data standardization or normalization processes. Then, a detailed logical explanation was given, the definition of continuous trend labeling was proposed and also an automatic labeling algorithm was given to extract the continuous trend features of financial time series data. Experiments on the Shanghai Composite Index and Shenzhen Component Index and some stocks of China showed that our labeling method is a much better state-of-the-art labeling method in terms of classification accuracy and some other classification evaluation metrics. The results of the paper also proved that deep learning models such as LSTM and GRU are more suitable for dealing with the prediction of financial time series data.},
  DOI = {10.3390/e22101162}
}

@article{BBCGoogleApology2015,
  title = {Google apologises for Photos app's racist blunder},
  author = {{BBC News}},
  year = {2015},
  month = {July},
  url = {https://www.bbc.com/news/technology-33347866},
  journal = {BBC News},
  note = {Accessed on October 09, 2024}
}

@article{AngwinLarsonMattuKirchner2016,
  title = {How We Analyzed the {COMPAS} Recidivism Algorithm},
  author = {Angwin, Julia and Larson, Jeff and Mattu, Surya and Kirchner, Lauren},
  year = {2016},
  month = {May},
  journal = {ProPublica},
  url = {https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm},
  note = {Accessed on October 09, 2024}
}

@article{HaoKarBuolamwini2019,
  title = {Can you make {AI} fairer than a judge? {Play} our courtroom algorithm game},
  author = {Hao, Karen and Kar, Jonathan and Buolamwini, Joy},
  year = {2019},
  month = {October},
  journal = {MIT Technology Review},
  url = {https://www.technologyreview.com/2019/10/17/75285/ai-fairer-than-judge-criminal-risk-assessment-algorithm/amp/},
  note = {Accessed on October 09, 2024}
}

@article{doi:10.1126/sciadv.aao5580,
  author = {Julia Dressel  and Hany Farid },
  title = {The accuracy, fairness, and limits of predicting recidivism},
  journal = {Science Advances},
  volume = {4},
  number = {1},
  pages = {eaao5580},
  year = {2018},
  doi = {10.1126/sciadv.aao5580},
  URL = {https://www.science.org/doi/abs/10.1126/sciadv.aao5580},
  eprint = {https://www.science.org/doi/pdf/10.1126/sciadv.aao5580},
  abstract = {Should we trust computers to make life-altering decisions in the criminal justice system? Algorithms for predicting recidivism are commonly used to assess a criminal defendant’s likelihood of committing a crime. These predictions are used in pretrial, parole, and sentencing decisions. Proponents of these systems argue that big data and advanced machine learning make these analyses more accurate and less biased than humans. We show, however, that the widely used commercial risk assessment software COMPAS is no more accurate or fair than predictions made by people with little or no criminal justice expertise. In addition, despite COMPAS’s collection of 137 features, the same accuracy can be achieved with a simple linear classifier with only two features.}
}

@misc{zheng2024sglangefficientexecutionstructured,
  title={SGLang: Efficient Execution of Structured Language Model Programs},
  author={Lianmin Zheng and Liangsheng Yin and Zhiqiang Xie and Chuyue Sun and Jeff Huang and Cody Hao Yu and Shiyi Cao and Christos Kozyrakis and Ion Stoica and Joseph E. Gonzalez and Clark Barrett and Ying Sheng},
  year={2024},
  eprint={2312.07104},
  archivePrefix={arXiv},
  primaryClass={cs.AI},
  url={https://arxiv.org/abs/2312.07104},
}

@misc{tang2024razorattentionefficientkvcache,
  title={RazorAttention: Efficient KV Cache Compression Through Retrieval Heads},
  author={Hanlin Tang and Yang Lin and Jing Lin and Qingsen Han and Shikuan Hong and Yiwu Yao and Gongyi Wang},
  year={2024},
  eprint={2407.15891},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2407.15891},
}

@misc{zhang2023h2oheavyhitteroracleefficient,
  title={H$_2$O: Heavy-Hitter Oracle for Efficient Generative Inference of Large Language Models},
  author={Zhenyu Zhang and Ying Sheng and Tianyi Zhou and Tianlong Chen and Lianmin Zheng and Ruisi Cai and Zhao Song and Yuandong Tian and Christopher Ré and Clark Barrett and Zhangyang Wang and Beidi Chen},
  year={2023},
  eprint={2306.14048},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2306.14048},
}

@misc{liu2023scissorhandsexploitingpersistenceimportance,
  title={Scissorhands: Exploiting the Persistence of Importance Hypothesis for LLM KV Cache Compression at Test Time},
  author={Zichang Liu and Aditya Desai and Fangshuo Liao and Weitao Wang and Victor Xie and Zhaozhuo Xu and Anastasios Kyrillidis and Anshumali Shrivastava},
  year={2023},
  eprint={2305.17118},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2305.17118},
}

@misc{li2024snapkvllmknowslooking,
  title={SnapKV: LLM Knows What You are Looking for Before Generation},
  author={Yuhong Li and Yingbing Huang and Bowen Yang and Bharat Venkitesh and Acyr Locatelli and Hanchen Ye and Tianle Cai and Patrick Lewis and Deming Chen},
  year={2024},
  eprint={2404.14469},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2404.14469},
}

@misc{cai2024pyramidkvdynamickvcache,
  title={PyramidKV: Dynamic KV Cache Compression based on Pyramidal Information Funneling},
  author={Zefan Cai and Yichi Zhang and Bofei Gao and Yuliang Liu and Tianyu Liu and Keming Lu and Wayne Xiong and Yue Dong and Baobao Chang and Junjie Hu and Wen Xiao},
  year={2024},
  eprint={2406.02069},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2406.02069},
}

@misc{feng2024adakvoptimizingkvcache,
  title={Ada-KV: Optimizing KV Cache Eviction by Adaptive Budget Allocation for Efficient LLM Inference},
  author={Yuan Feng and Junlin Lv and Yukun Cao and Xike Xie and S. Kevin Zhou},
  year={2024},
  eprint={2407.11550},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2407.11550},
}

@misc{xiao2024efficientstreaminglanguagemodels,
  title={Efficient Streaming Language Models with Attention Sinks},
  author={Guangxuan Xiao and Yuandong Tian and Beidi Chen and Song Han and Mike Lewis},
  year={2024},
  eprint={2309.17453},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2309.17453},
}

@misc{ainslie2023gqatraininggeneralizedmultiquery,
  title={GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints},
  author={Joshua Ainslie and James Lee-Thorp and Michiel de Jong and Yury Zemlyanskiy and Federico Lebrón and Sumit Sanghai},
  year={2023},
  eprint={2305.13245},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2305.13245},
}

@misc{ge2024modeltellsdiscardadaptive,
  title={Model Tells You What to Discard: Adaptive KV Cache Compression for LLMs},
  author={Suyu Ge and Yunan Zhang and Liyuan Liu and Minjia Zhang and Jiawei Han and Jianfeng Gao},
  year={2024},
  eprint={2310.01801},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2310.01801},
}

@misc{rajamanoharan2024improvingdictionarylearninggated,
  title={Improving Dictionary Learning with Gated Sparse Autoencoders},
  author={Senthooran Rajamanoharan and Arthur Conmy and Lewis Smith and Tom Lieberum and Vikrant Varma and János Kramár and Rohin Shah and Neel Nanda},
  year={2024},
  eprint={2404.16014},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2404.16014},
}

@misc{rajamanoharan2024jumpingaheadimprovingreconstruction,
  title={Jumping Ahead: Improving Reconstruction Fidelity with JumpReLU Sparse Autoencoders},
  author={Senthooran Rajamanoharan and Tom Lieberum and Nicolas Sonnerat and Arthur Conmy and Vikrant Varma and János Kramár and Neel Nanda},
  year={2024},
  eprint={2407.14435},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2407.14435},
}

@online{sharkey2024feature,
  title = {Addressing Feature Suppression in {SAEs}},
  author = {Sharkey, Lee},
  year = {2024},
  url = {https://www.alignmentforum.org/posts/3JuSjTZyMzaSeTxKk/addressing-feature-suppression-in-saes},
  urldate = {2024-10-31},
  organization = {AI Alignment Forum},
  note = {Produced as part of the ML Alignment Theory Scholars Program - Winter 2023-24 Cohort}
}

@misc{shazeer2020gluvariantsimprovetransformer,
  title={GLU Variants Improve Transformer},
  author={Noam Shazeer},
  year={2020},
  eprint={2002.05202},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2002.05202},
}

@misc{dauphin2017languagemodelinggatedconvolutional,
  title={Language Modeling with Gated Convolutional Networks},
  author={Yann N. Dauphin and Angela Fan and Michael Auli and David Grangier},
  year={2017},
  eprint={1612.08083},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/1612.08083},
}

@misc{erichson2019jumpreluretrofitdefensestrategy,
  title={JumpReLU: A Retrofit Defense Strategy for Adversarial Attacks},
  author={N. Benjamin Erichson and Zhewei Yao and Michael W. Mahoney},
  year={2019},
  eprint={1904.03750},
  archivePrefix={arXiv},
  primaryClass={cs.CR},
  url={https://arxiv.org/abs/1904.03750},
}

@misc{nanda2023progressmeasuresgrokkingmechanistic,
  title={Progress measures for grokking via mechanistic interpretability},
  author={Neel Nanda and Lawrence Chan and Tom Lieberum and Jess Smith and Jacob Steinhardt},
  year={2023},
  eprint={2301.05217},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2301.05217},
}

@misc{power2022grokkinggeneralizationoverfittingsmall,
  title={Grokking: Generalization Beyond Overfitting on Small Algorithmic Datasets},
  author={Alethea Power and Yuri Burda and Harri Edwards and Igor Babuschkin and Vedant Misra},
  year={2022},
  eprint={2201.02177},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2201.02177},
}

@misc{ramachandran2017searchingactivationfunctions,
  title={Searching for Activation Functions},
  author={Prajit Ramachandran and Barret Zoph and Quoc V. Le},
  year={2017},
  eprint={1710.05941},
  archivePrefix={arXiv},
  primaryClass={cs.NE},
  url={https://arxiv.org/abs/1710.05941},
}

@software{yangbentoml2022,
  author = {Yang, Chaoyu and Sheng Sean and Pham Aaron and  Zhao Shenyang and Lee Sauyon and Jiang Bo and Dong Fog and Guan Xipeng and Ming Frost},
  license = {Apache-2.0},
  title = {{BentoML: The framework for building reliable, scalable and cost-efficient AI application}},
  url = {https://github.com/bentoml/BentoML}
}

@misc{gorton2024missingcurvedetectorsinceptionv1,
  title={The Missing Curve Detectors of InceptionV1: Applying Sparse Autoencoders to InceptionV1 Early Vision},
  author={Liv Gorton},
  year={2024},
  eprint={2406.03662},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2406.03662},
}

@misc{panickssery2024steeringllama2contrastive,
  title={Steering Llama 2 via Contrastive Activation Addition},
  author={Nina Panickssery and Nick Gabrieli and Julian Schulz and Meg Tong and Evan Hubinger and Alexander Matt Turner},
  year={2024},
  eprint={2312.06681},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2312.06681},
}

@misc{turner2024steeringlanguagemodelsactivation,
  title={Steering Language Models With Activation Engineering},
  author={Alexander Matt Turner and Lisa Thiergart and Gavin Leech and David Udell and Juan J. Vazquez and Ulisse Mini and Monte MacDiarmid},
  year={2024},
  eprint={2308.10248},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2308.10248},
}

@article{doi:10.1080/09515080050002726,
  author = {Aarre Laakso and Garrison Cottrell},
  title = {Content and cluster analysis: Assessing representational similarity in neural systems},
  journal = {Philosophical Psychology},
  volume = {13},
  number = {1},
  pages = {47--76},
  year = {2000},
  publisher = {Routledge},
  doi = {10.1080/09515080050002726},
  URL = {https://doi.org/10.1080/09515080050002726},
  eprint = {https://doi.org/10.1080/09515080050002726}
}

@misc{raghu2017svccasingularvectorcanonical,
  title={SVCCA: Singular Vector Canonical Correlation Analysis for Deep Learning Dynamics and Interpretability},
  author={Maithra Raghu and Justin Gilmer and Jason Yosinski and Jascha Sohl-Dickstein},
  year={2017},
  eprint={1706.05806},
  archivePrefix={arXiv},
  primaryClass={stat.ML},
  url={https://arxiv.org/abs/1706.05806},
}

@misc{lenc2015understandingimagerepresentationsmeasuring,
  title={Understanding image representations by measuring their equivariance and equivalence},
  author={Karel Lenc and Andrea Vedaldi},
  year={2015},
  eprint={1411.5908},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/1411.5908},
}

@inproceedings {280922,
  author = {Gyeong-In Yu and Joo Seong Jeong and Geon-Woo Kim and Soojeong Kim and Byung-Gon Chun},
  title = {Orca: A Distributed Serving System for {Transformer-Based} Generative Models},
  booktitle = {16th USENIX Symposium on Operating Systems Design and Implementation (OSDI 22)},
  year = {2022},
  isbn = {978-1-939133-28-1},
  address = {Carlsbad, CA},
  pages = {521--538},
  url = {https://www.usenix.org/conference/osdi22/presentation/yu},
  publisher = {USENIX Association},
  month = jul
}

@article{resnick2018cambridge,
  title={Cambridge Analytica’s “psychographic microtargeting”: what’s bullshit and what’s legit},
  author={Resnick, Brian},
  journal={Vox},
  year={2018},
  url={https://www.vox.com/science-and-health/2018/3/23/17152564/cambridge-analytica-psychographic-microtargeting-what}
}

@article{zuboff2020surveillance,
  title={Surveillance Capitalism},
  author={Zuboff, Shoshana},
  journal={Project Syndicate},
  year={2020},
  url={https://www.project-syndicate.org/magazine/surveillance-capitalism-exploiting-behavioral-data-by-shoshana-zuboff-2020-01}
}

@article{doi:10.1057/jit.2015.5,
  author = {Shoshana Zuboff},
  title ={Big other: Surveillance Capitalism and the Prospects of an Information Civilization},
  journal = {Journal of Information Technology},
  volume = {30},
  number = {1},
  pages = {75-89},
  year = {2015},
  doi = {10.1057/jit.2015.5},
  URL = {https://doi.org/10.1057/jit.2015.5},
  eprint = {https://doi.org/10.1057/jit.2015.5},
  abstract = {This article describes an emergent logic of accumulation in the networked sphere, ‘surveillance capitalism,’ and considers its implications for ‘information civilization.’ The institutionalizing practices and operational assumptions of Google Inc. are the primary lens for this analysis as they are rendered in two recent articles authored by Google Chief Economist Hal Varian. Varian asserts four uses that follow from computer-mediated transactions: data extraction and analysis,’ ‘new contractual forms due to better monitoring,’ ‘personalization and customization, ’ and continuous experiments. ’ An examination of the nature and consequences of these uses sheds light on the implicit logic of surveillance capitalism and the global architecture of computer mediation upon which it depends. This architecture produces a distributed and largely uncontested new expression of power that I christen: Big Other. ’ It is constituted by unexpected and often illegible mechanisms of extraction, commodification, and control that effectively exile persons from their own behavior while producing new markets of behavioral prediction and modification. Surveillance capitalism challenges democratic norms and departs in key ways from the centuries-long evolution of market capitalism.}
}

@article{8436400,
  author={Isaak, Jim and Hanna, Mina J.},
  journal={Computer},
  title={User Data Privacy: Facebook, Cambridge Analytica, and Privacy Protection},
  year={2018},
  volume={51},
  number={8},
  pages={56-59},
  abstract={With the revelation that Facebook handed over personally identifiable information of more than 87 million users to Cambridge Analytica, it is now imperative that comprehensive privacy policy laws be developed. Technologists, researchers, and innovators should meaningfully contribute to the development of these policies.},
  keywords={data privacy;Facebook;Cambridge Analytica;user data privacy;privacy protection;The Policy Corner;Internet/Web technologies;security;online security;data security;privacy;cybercrime;social media;PII;personally identifiable information},
  doi={10.1109/MC.2018.3191268},
  ISSN={1558-0814},
  month={August},
}

@book{zuboff2019age,
  title={The Age of Surveillance Capitalism: The Fight for a Human Future at the New Frontier of Power},
  author={Zuboff, Shoshana},
  year={2019},
  publisher={PublicAffairs},
  address={New York, NY},
  isbn={9781781256855}
}

@article{srnicek2017platformcapitalism,
  author = {Srnicek, Nick},
  title = {The challenges of platform capitalism: Understanding the logic of a new business model},
  journal = {Juncture},
  volume = {23},
  number = {4},
  pages = {254-257},
  doi = {https://doi.org/10.1111/newe.12023},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/newe.12023},
  eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/newe.12023},
  abstract = {The platform business model is predicated upon a voracious appetite for data that can only be sated by disregard for privacy (and often workers' rights), and constant outward expansion. As they become ever more central to the global economy, Nick Srnicek argues that it's incumbent on us to understand how they function.},
  year = {2017}
}

@book{couldry2019costs,
  title={The Costs of Connection: How Data Is Colonizing Human Life and Appropriating It for Capitalism},
  author={Couldry, Nick and Mejias, Ulises A.},
  year={2019},
  publisher={Stanford University Press},
  address={Stanford, CA},
  isbn={978-1-5036-0366-0},
  url={https://www.sup.org/books/sociology/costs-connection}
}

@article{susser2019technology,
  title={Technology, autonomy, and manipulation},
  author={Susser, Daniel and Roessler, Beate and Nissenbaum, Helen},
  journal={Internet Policy Review},
  volume={8},
  number={2},
  year={2019},
  doi={10.14763/2019.2.1410},
  url={https://policyreview.info/articles/analysis/technology-autonomy-and-manipulation}
}

@article{10.1257/jel.54.2.442,
  Author = {Acquisti, Alessandro and Taylor, Curtis and Wagman, Liad},
  Title = {The Economics of Privacy},
  Journal = {Journal of Economic Literature},
  Volume = {54},
  Number = {2},
  Year = {2016},
  Month = {June},
  Pages = {442–92},
  DOI = {10.1257/jel.54.2.442},
  URL = {https://www.aeaweb.org/articles?id=10.1257/jel.54.2.442}
}

@article{vandekerckhove2012organize,
  title={Can We Organize Courage? Implications from Foucault's Parrhesia},
  author={Vandekerckhove, Wim and Langenberg, Suzan},
  journal={Electronic Journal of Business Ethics and Organizational Studies},
  year={2012},
  url={https://ssrn.com/abstract=2005662}
}

@misc{willard2023efficientguidedgenerationlarge,
  title={Efficient Guided Generation for Large Language Models},
  author={Brandon T. Willard and Rémi Louf},
  year={2023},
  eprint={2307.09702},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2307.09702},
}

@misc{chen2023acceleratinglargelanguagemodel,
  title={Accelerating Large Language Model Decoding with Speculative Sampling},
  author={Charlie Chen and Sebastian Borgeaud and Geoffrey Irving and Jean-Baptiste Lespiau and Laurent Sifre and John Jumper},
  year={2023},
  eprint={2302.01318},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2302.01318},
}

@misc{liu2023ringattentionblockwisetransformers,
  title={Ring Attention with Blockwise Transformers for Near-Infinite Context},
  author={Hao Liu and Matei Zaharia and Pieter Abbeel},
  year={2023},
  eprint={2310.01889},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2310.01889},
}

@misc{lew2023sequentialmontecarlosteering,
  title={Sequential Monte Carlo Steering of Large Language Models using Probabilistic Programs},
  author={Alexander K. Lew and Tan Zhi-Xuan and Gabriel Grand and Vikash K. Mansinghka},
  year={2023},
  eprint={2306.03081},
  archivePrefix={arXiv},
  primaryClass={cs.AI},
  url={https://arxiv.org/abs/2306.03081},
}

@article{blair2015ofcorporations,
 ISSN = {1052150X},
 URL = {http://www.jstor.org/stable/43973409},
 abstract = {Since the dawn of capitalism, corporations have been regarded by the law as separate legal "persons." Corporate "personhood" has nonetheless remained controversial, and our understanding of corporate personhood often influences our thinking about the social responsibilities of corporations. This essay, written in honor of Prof. Thomas Donaldson, explores the tension in recent decisions by the U.S. Supreme Court and the Delaware Chancery Court about what corporations are, whose interests they serve, and who gets to make decisions about what they do. These decisions suggest that the law does not unequivocally support Donaldson's vision of corporations as "moral" persons.},
 author = {Margaret M. Blair},
 journal = {Business Ethics Quarterly},
 number = {4},
 pages = {415--431},
 publisher = {Cambridge University Press},
 title = {Of Corporations, Courts, Personhood, and Morality},
 urldate = {2024-11-19},
 volume = {25},
 year = {2015}
}

@misc{marshall2024refusalllmsaffinefunction,
  title={Refusal in LLMs is an Affine Function},
  author={Thomas Marshall and Adam Scherlis and Nora Belrose},
  year={2024},
  eprint={2411.09003},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2411.09003},
}

@article{Donaldson1984Corporation,
	author = {Thomas Donaldson},
	doi = {10.2307/2215231},
	journal = {No\^{u}s},
	number = {3},
	pages = {548--551},
	publisher = {Wiley-Blackwell},
	title = {Corporations \& Morality},
	volume = {18},
	year = {1984}
}

@article{https://doi.org/10.1111/j.1468-2370.2009.00275.x,
  author = {Carroll, Archie B. and Shabana, Kareem M.},
  title = {The Business Case for Corporate Social Responsibility: A Review of Concepts, Research and Practice},
  journal = {International Journal of Management Reviews},
  volume = {12},
  number = {1},
  pages = {85-105},
  doi = {https://doi.org/10.1111/j.1468-2370.2009.00275.x},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1468-2370.2009.00275.x},
  eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1468-2370.2009.00275.x},
  abstract = {In this review, the primary subject is the ‘business case’ for corporate social responsibility (CSR). The business case refers to the underlying arguments or rationales supporting or documenting why the business community should accept and advance the CSR ‘cause’. The business case is concerned with the primary question: What do the business community and organizations get out of CSR? That is, how do they benefit tangibly from engaging in CSR policies, activities and practices? The business case refers to the bottom-line financial and other reasons for businesses pursuing CSR strategies and policies. In developing this business case, the paper first provides some historical background and perspective. In addition, it provides a brief discussion of the evolving understandings of CSR and some of the long-established, traditional arguments that have been made both for and against the idea of business assuming any responsibility to society beyond profit-seeking and maximizing its own financial well-being. Finally, the paper addresses the business case in more detail. The goal is to describe and summarize what the business case means and to review some of the concepts, research and practice that have come to characterize this developing idea.},
  year = {2010}
}

@book{Kant1785KANGFT,
	address = {New York},
	author = {Immanuel Kant},
	editor = {Thomas E. Hill and Arnulf Zweig},
	publisher = {Oxford University Press},
	title = {Groundwork for the Metaphysics of Morals},
	year = {1785}
}

@article{friedman1970social,
  title={The Social Responsibility of Business is to Increase its Profits},
  author={Friedman, Milton},
  journal={The New York Times Magazine},
  year={1970},
  month={September 13}
}

@article{strine2015corporate,
  title={Corporate Power Ratchet: The Courts' Role in Eroding 'We the People's' Ability to Constrain Our Corporate Creations},
  author={Strine Jr, Leo E.},
  journal={Harvard Civil Rights-Civil Liberties Law Review},
  year={2015},
  volume={51},
  pages={423}
}

@book{deleuze1972anti,
  title={Anti-Oedipus: Capitalism and Schizophrenia},
  author={Deleuze, Gilles and Guattari, Félix},
  year={1972},
  publisher={Les Editions de Minuit}
}

@book{chomsky1999profit,
  title={Profit Over People: Neoliberalism and Global Order},
  author={Chomsky, Noam},
  year={1999},
  publisher={Seven Stories Press},
  address={New York},
  isbn={1-888363-82-7},
  price={US\$15.95}
}

@misc{sheng2024fairnessservinglargelanguage,
  title={Fairness in Serving Large Language Models},
  author={Ying Sheng and Shiyi Cao and Dacheng Li and Banghua Zhu and Zhuohan Li and Danyang Zhuo and Joseph E. Gonzalez and Ion Stoica},
  year={2024},
  eprint={2401.00588},
  archivePrefix={arXiv},
  primaryClass={cs.AI},
  url={https://arxiv.org/abs/2401.00588},
}

@misc{abdelkhalik2022demystifyingnvidiaamperearchitecture,
  title={Demystifying the Nvidia Ampere Architecture through Microbenchmarking and Instruction-level Analysis},
  author={Hamdy Abdelkhalik and Yehia Arafa and Nandakishore Santhi and Abdel-Hameed Badawy},
  year={2022},
  eprint={2208.11174},
  archivePrefix={arXiv},
  primaryClass={cs.AR},
  url={https://arxiv.org/abs/2208.11174},
}

@inproceedings{novikoff1962convergence,
  author    = {Albert B. J. Novikoff},
  title     = {On Convergence Proofs for Perceptrons},
  booktitle = {Proceedings of the Symposium on the Mathematical Theory of Automata},
  year      = {1962},
  pages     = {615--622},
  volume    = {12},
  publisher = {Polytechnic Institute of Brooklyn},
  address   = {New York, NY, USA},
  url       = {https://apps.dtic.mil/sti/tr/pdf/AD0298258.pdf}
}

@book{mcconnell2014applications,
  title={Applications of Tensor Analysis},
  author={McConnell, A.J.},
  isbn={9780486145020},
  url={https://books.google.ca/books?id=ZCP0AwAAQBAJ},
  year={2014},
  publisher={Dover Publications}
}

@book{schouten1951tensor,
  author = {Schouten, Jan Arnoldus},
  title = {Tensor Analysis for Physicists},
  year = {1951},
  publisher = {Oxford University Press},
  address = {Oxford}
}

@article{mitchell1912backwardartofspendingmoney,
 ISSN = {00028282},
 URL = {http://www.jstor.org/stable/1827579},
 author = {Wesley C. Mitchell},
 journal = {The American Economic Review},
 number = {2},
 pages = {269--281},
 publisher = {American Economic Association},
 title = {The Backward Art of Spending Money},
 urldate = {2024-11-27},
 volume = {2},
 year = {1912}
}

@book{friedman1962capitalism,
  title={Capitalism and Freedom},
  author={Friedman, Milton and Friedman, Rose D.},
  year={1962},
  publisher={University of Chicago Press},
  address={Chicago},
  pages={202},
  isbn={9780226264004}
}

@misc{PEAct1990,
  title={Professional Engineers Act, R.S.O. 1990, c. P.28},
  author={{Government of Ontario}},
  year={1990},
  publisher={Government of Ontario},
  note={Last amendment: 2024, c. 2, Sched. 1, s. 20}
}

@book{wittgenstein1953philosophical,
  title={Philosophical Investigations},
  author={Wittgenstein, Ludwig},
  year={1953},
  publisher={Blackwell},
  address={Oxford},
  translator={Anscombe, G. E. M.},
  note={Translated from the German "Philosophische Untersuchungen"},
  isbn={0631103201}
}
